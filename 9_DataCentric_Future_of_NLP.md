# 🧠 Data-Centric NLP의 미래 전망

> 미래의 NLP 발전 방향은 **데이터 중심적 접근(Data-Centric AI)** 을 기반으로,  
> 다양한 모달리티, 인간적 피드백, 추론 기반 AI로 확장될 것으로 예상됩니다.

---

## **1️⃣ Multi-Modal AI (멀티모달 인공지능)**

### 📘 정의
Multi-Modal AI는 **텍스트, 이미지, 오디오, 비디오 등 서로 다른 유형의 데이터를 통합 처리**하여  
더 정확하고 사람과 유사한 판단을 내리는 인공지능 기술입니다.

- 단일 모달(Uni-Modal) 데이터만으로는 현실 세계의 복잡한 문제를 해결하기 어렵기 때문에  
  서로 다른 데이터의 장점을 결합해 **노이즈 보정 및 성능 향상**을 기대할 수 있습니다.
- 예시:  
  - 의료 영상 + 환자 기록을 결합한 진단  
  - 자율주행 차량의 시각·언어·센서 데이터 통합  
  - 이미지 기반 질의응답(VQA) 시스템  
  - 인간-로봇 상호작용(HRI) 등

### ⚙️ 필요성
- 다양한 현실 데이터를 함께 처리해야 **추론, 설명력, 신뢰성**이 강화됨  
- 텍스트만으로 표현되지 않는 **시각적, 청각적, 공간적 정보**를 반영 가능  
- 멀티모달 데이터의 결합으로 **모델의 일반화 능력 및 Robustness 향상**

### 📊 대표적인 Multi-Modal 데이터셋

| 분야 | 데이터셋 | 설명 |
|------|------------|------|
| **시각적 질문응답 (VQA)** | VQA v2.0, OK-VQA | 이미지 기반 질문-답변, 외부 지식 필요 |
| **시각적 상식 추론 (VCR)** | VCR | 이미지 속 상황 이해 및 추론 |
| **이미지 기반 대화 (Visual Dialog)** | Visual Dialog, DialogCC, MMDialog | 이미지와 텍스트가 결합된 대화 데이터 |
| **텍스트 기반 시각 질의응답** | TextVQA, TextCaps | 이미지 내 텍스트 인식 및 이해 |
| **수학·논리 추론** | GSM8K, CLEVR-Math | 언어+시각 정보를 이용한 수학 문제 해결 |
| **비디오 이해** | MSR-VTT, SumMe, VidLN | 비디오와 자연어 간 연계 |
| **이미지 생성** | FFHQ-Text | 텍스트-얼굴 이미지 매핑 데이터 |

---

## **2️⃣ Neuro-Symbolic AI (뉴로-심볼릭 인공지능)**

### 📘 정의
Neuro-Symbolic AI는 **신경망(Neural Network)의 학습 능력**과  
**기호적(Symbolic) AI의 논리적 추론 능력**을 결합한 접근 방식입니다.

- **Neural AI:** 대규모 데이터에서 패턴을 학습 (예: 딥러닝, LLM 등)  
- **Symbolic AI:** 논리 규칙, 지식 그래프를 활용한 명시적 추론  
- 두 방식을 결합하면 **데이터 기반 학습 + 규칙 기반 추론**이 가능한 모델 구축 가능

### ⚙️ 작동 방식
1. **Neural Layer**가 데이터를 분석하여 패턴과 표현을 학습  
2. **Symbolic Layer**가 이를 기반으로 논리적 관계를 추론  
3. 두 계층이 상호 보완적으로 작동하여 해석 가능하고 일반화 가능한 추론 수행

### 💡 필요성
- LLM과 같은 통계적 모델은 “왜”라는 질문에 대한 추론이 부족  
- Symbolic AI는 데이터 확장성 부족  
- 결합을 통해 **설명 가능성(Explainability)** 과 **지식 기반 추론(Reasoning)** 강화

### 📚 대표 연구
| 연구명 | 내용 |
|---------|------|
| **The Neuro-Symbolic Concept Learner** (ICLR 2019) | 자연 감독(supervision) 하에 장면·단어·문장 해석 |
| **ATOMIC / ConceptNet 5.5** | 상식 지식 그래프 구축 |
| **COMET** (ACL 2019) | 트랜스포머 기반 자동 상식 추론 모델 |
| **SODA** (2022) | 대규모 대화 데이터에서 사회적 상식 추론 |
| **Neuro-Symbolic Procedural Planning** (ICLR 2023) | 상식 기반 절차적 추론 및 계획 수립 |

---

## **3️⃣ RLHF (Reinforcement Learning with Human Feedback)**

### 📘 정의
RLHF는 **인간의 피드백을 학습 보상으로 활용하는 강화학습 기법**입니다.  
이는 "좋은 텍스트"를 명시적으로 정의하기 어려운 문제를 해결하기 위한 방법입니다.

### ⚙️ 작동 과정
1. **사전 학습 (Pretraining):** 대규모 텍스트로 언어모델 훈련  
2. **지도 미세조정 (SFT):** 사람이 작성한 “좋은 응답”으로 감독학습  
3. **보상 모델 훈련 (Reward Model):** 여러 응답 중 인간이 선호한 것을 학습  
4. **강화학습 (RL with PPO):** 보상 모델을 기준으로 언어모델 최적화

### 🧠 효과
- 생성된 문장의 **자연스러움·안전성** 향상  
- 사용자 피드백 반영으로 **인간 친화적 대화 품질** 개선  
- ChatGPT의 핵심 기술로 활용됨

---

## **4️⃣ GPT-4**

### 📘 특징 요약
| 항목 | 설명 |
|------|------|
| **Multi-Modal 입력** | 텍스트 + 이미지 입력 모두 처리 가능 |
| **향상된 추론 능력** | 복잡한 수리·논리 문제 해결 가능 |
| **창의성 (Creativity)** | 에세이, 코드, 시각적 설명 등 다양한 형식 생성 |
| **긴 컨텍스트 처리** | 수만 토큰 단위 문맥 유지 |
| **RLHF 적용** | 인간 피드백을 통한 안전한 출력 제어 |

### ⚠️ 한계점
- **환각(Hallucination):** 사실과 다른 정보 생성 가능  
- **사회적 편향(Bias):** 학습 데이터의 한계 반영  
- **지식 제한:** 2022년 9월까지의 데이터 기반  

---

## 💬 결론

> **Data-Centric NLP의 미래**는 다음 네 가지 축으로 발전 중입니다.
> 1. **Multi-Modal AI** — 인간과 유사한 감각 통합 이해  
> 2. **Neuro-Symbolic AI** — 논리적 추론과 학습의 융합  
> 3. **RLHF** — 인간 피드백을 통한 신뢰성 향상  
> 4. **GPT-4 이후의 LLM** — 초대규모 멀티모달 모델의 확장  

이러한 기술들은 단순한 모델 성능을 넘어,  
**데이터 품질과 인간 중심의 AI 발전**에 초점을 맞추고 있습니다.
